# Dynamic AOI Toolkit

This toolkit includes tools to measure dynamic areas of interest (AOI) on a widescreen based on the Pupil Labs Core eye tracker data. The tools included are: (1) AOI selector (both automatic and manual), (2) overlay AOIs and gaze on the task presented and (3) AOI hit detection.

## Table of Contents

1. [Installation](#installation)
1. [Usage](#usage)
   1. [Data structure](#1-data-structure-data-folder)
   1. [AOI Selector](#2-aoi-selector)
      1. Method 1: Tracking objects semi-automatically
      1. Method 2: Selection AOI
      1. Combining the AOI Selector output
   1. [AOI Overlay](#3-aoi-overlay)
      1. Overlaying AOIS over a video
      1. Overlaying AOIS and gaze positions over a video
      1. Overlaying gaze positions of multiple participants and AOIs over a video
   1. [AOI Hit detection](#4-aoi-hit-detection)
      1. Analyse metrics such as dwell time, time to first entry etc.
      1. Merge outputs
   1. [Apriltags overlay on video](#5-apriltags-overlay-on-video)
1. [Contribution](#3-contribution)
1. [License](#4-license)

## Installation

To use the toolkit, make sure python3 is installed. To install the latest version of this toolkit, use:

```bash
git clone git@github.com:treyescan/dynamic-aoi-toolkit.git

pip3 install -m requirements.txt
```

After this, open `__constants.py` and change the variable `data_folder` to point to the data folder as structured below.

## Usage

### 1. Data structure (data folder)

- `data/`
  &nbsp;
  - `input-aoi/` – all files related to the AOIs
    - task1_aois.csv
    - _... (more aois)_
      &nbsp;
  - `input-gp/` – all files related to input data from Pupil Labs
    - [example-participant](/data/input-gp/example-participant/README.md)
    - P-001/
      - task1/
        - n surfaces from Pupil Labs
        - dummy surface from Pupil Labs
        - synchronization surface from Pupil Labs
        - gp.csv (generated by tools/analysis)
      - _... (more tasks)_
    - _... (more participants)_
      &nbsp;
  - `output/` – all output files
    - P-001/
      - task1/
        - number_of_filtered_rows.txt
        - gp_x_aoi.csv
        - entries_exits.json
        - outputfile.csv
      - _... (more task)_
    - _... (more participants)_
      &nbsp;
  - `videos/` – all videos
    - start_end_frames/
      - synchronization/
        - task1.json (this file contains start and end frame numbers of all synchronization surfaces)
        - _... (more tasks)_
    - task1.mp4
    - _... (more videos)_

### 2. AOI Selector

The AOI Selector allow the user to define dynamic AOIs. This can be done semi-automatically or manually. Both methods can be used intertwined, after which the data files can be combined. We can check the data files by overlaying the csv files over a video in the AOI overlay tool.

#### Method 1: Tracking objects semi-automatically

```bash
python3 aoi_tracking.py --video="video.mp4" --start_frame=70
```

**_Usage:_**

1. Run the command above, replacing `vid.mp4` with the path to your video
1. The video will open a preview screen
1. If you want to select an object to track from the first frame, draw a box on the video
1. If not: hint `[enter]` to play the video, hit `[s]` when you want to select an object
1. The video starts playing and shows the tracked object. In this state, the results are directly saved to your output csv
1. When you're done, stop the script by hitting `[q]`

#### Method 2: Selection AOI

```bash
# use this to select  frames and let the script interpolate the frames in between
python3 aoi_selection.py --video="video.mp4" --start_frame=100

# use this to select each frame manually
python3 aoi_selection.py --video="video.mp4" --start_frame=100 --manual
```

**_Usage:_**

1. Run the command above, replacing `videos/vid.mp4` with the path to your video
1. The video will open a preview screen
1. If you want to select a AOI from the first frame
1. If not: hint `[enter]` to play the video, hit `[s]` when you want to select a AOI
1. The video starts playing **without** showing the AOI. when you want to select a new AOI, hit `[s]`
1. When you're done, stop the script by hitting `[q]`
1. The script will print the selected bounding boxes to the console and calculate the coordinates of the AOI in between
1. The script will show you the computed AOI's by showing the video again and save it to the output file.

#### Combining the AOI Selector output

```bash
python3 concat_files.py --folder data/testvideo
```

**_Usage:_**

1. Make sure all output files from script 1 and 2 are saved in one folder
1. Run the command above, replacing data/testvideo` with the path to your output folder
1. The files will be concatenated to a single file (`combined_data/dataset.csv`). The console will show you the path of this file

### 3. AOI Overlay

In AOI overlay, 3 tools are presented in order to display selected AOIs and gaze positions. The scripts overlay each frame of the task with information, depending on the chosen tool. Options include: only AOIs, AOIs + gaze of one participant and AOIs + gaze data of all available participants.

#### Overlaying AOIS over a video

```bash
cd tools/overlay/
python3 overlay_only_aois.py --video="video.mp4" --aois="aois.csv" --start_frame=1000
```

**_Usage:_**

1. Run the command above
1. The video will be outputted to `video_with_labels.mp4` in the same folder
1. Make sure to move this video before creating a new video
   1. NB: video processing make take a while since every frame has to be processed at full resolution

#### Overlaying AOIs and gaze positions over a video

```bash
# for one participant
cd tools/overlay/
python3 overlay_single_participant.py --video="video.mp4" --aois="aois.csv" --participant="{folder to particpant}" --start_frame=800
```

**_Usage:_**

1. Run the command above
1. The video will be outputted to `video_with_labels_and_gaze.mp4` in the same folder
1. Make sure to move this video before creating a new video
   1. NB: video processing make take a while since every frame has to be processed at full resolution

#### Overlaying gaze positions of multiple participants and AOIs over a video

```bash
# for multiple participants
cd tools/overlay/
python3 tools/overlay_multiple_participants.py --video="video.mp4" --aois="aois.csv" --task="{folder of participants}" --start_frame=800
```

**_Usage:_**

1. all gp.csv in {folder of participants} are fetched (last one)
1. output: video_with_multiple_gp.mp4
   1. NB: video processing make take a while since every frame has to be processed at full resolution

### 4. AOI Hit detection

<center><img src="flowchart.png" style="max-width: 300px" /></center>

AOI hit detection provides a tool to calculate measures such as dwell time and time to first entry. For every gaze position, the corresponding frame is checked for an AOI hit within the AOIs as defined by the AOI selectors. With merge_outputs.py the lastly generated output file of each participant is merged into one output file for statistical analysis purposes.

```bash
cd hit-detection
python3 analyse.py # this script will ask for all input and display where the output files are saved
```

**_Usage:_**

1. Put the data in the appropiate data folder (see Data structure)
1. Make sure all other files are in place:
   1. data/videos/synchronization/task.json

#### Merge outputs

```bash
cd hit-detection
python3 merge_outputs.py
```

**_Usage:_**

1. Make sure each participant folder has the file to be merged, as the newest output file in the folder.

### 5. Apriltags overlay on video

The goal of this part of the HPT toolset is to burn QR codes to a video so it can be used in the trials.

TODO: See script for usable params

#### Burn QR codes

```bash
python3 burn_qrs.py --name="../videos/vid.mp4" --cols=8 --rows=4 --default-scale=2
python3 burn_qrs.py --name="../videos/vid.mp4" --cols=8 --rows=4 --default-scale=2 --large-scale=4 --large-scale-indeces=16,18,17,19
```

**Usage:**

- In `/output` it will output the video with burned QR codes and it will provide a png with the QR codes

## 3. Contribution

[Issues](https://github.com/treyescan/dynamic-aoi-toolkit/issues/new) and other contributions are welcome.

## 4. License

This toolkit is licsensed under [GNU GENERAL PUBLIC LICENSE V3](/LICENSE)
